{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx (from -r requirements.txt (line 1))\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 2))\n",
      "  Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn (from -r requirements.txt (line 3))\n",
      "  Using cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from -r requirements.txt (line 4))\n",
      "  Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting openai (from -r requirements.txt (line 5))\n",
      "  Using cached openai-1.55.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv (from -r requirements.txt (line 6))\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting tqdm (from -r requirements.txt (line 7))\n",
      "  Using cached tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->-r requirements.txt (line 3))\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r requirements.txt (line 3))\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic-2.10.1-py3-none-any.whl.metadata (169 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 5))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting typing-extensions<5,>=4.11 (from openai->-r requirements.txt (line 5))\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5)) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 5))\n",
      "  Using cached pydantic_core-2.27.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-2.1.3-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp312-cp312-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached openai-1.55.0-py3-none-any.whl (389 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached jiter-0.7.1-cp312-cp312-macosx_11_0_arm64.whl (304 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached pydantic-2.10.1-py3-none-any.whl (455 kB)\n",
      "Using cached pydantic_core-2.27.1-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, tqdm, threadpoolctl, sniffio, python-dotenv, numpy, networkx, joblib, jiter, h11, distro, annotated-types, scipy, pydantic-core, httpcore, anyio, scikit-learn, pydantic, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 jiter-0.7.1 joblib-1.4.2 networkx-3.4.2 numpy-2.1.3 openai-1.55.0 pydantic-2.10.1 pydantic-core-2.27.1 python-dotenv-1.0.1 scikit-learn-1.5.2 scipy-1.14.1 sniffio-1.3.1 threadpoolctl-3.5.0 tqdm-4.67.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs saved to 'original_graph.json' and 'curated_graph.json'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akihiroinui/Projects/unnamed_project/.venv/lib/python3.12/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import json\n",
    "\n",
    "# Save Graph G1 to JSON\n",
    "def save_graph_to_json(graph, filename):\n",
    "    data = nx.readwrite.json_graph.node_link_data(graph)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Create Graph G1 (Original Instruction Graph)\n",
    "G1 = nx.DiGraph()\n",
    "\n",
    "# Add nodes with unique titles, types, and descriptions\n",
    "G1.add_node(\"Start\", type=\"start\", description=\"Inspect the electric vehicle for issues.\")\n",
    "G1.add_node(\"Battery Check\", type=\"multiple\", description=\"Is the battery charged?\")\n",
    "G1.add_node(\"Charge Battery\", type=\"process\", description=\"Charge the vehicle's battery.\")\n",
    "G1.add_node(\"Electrical System Check\", type=\"process\", description=\"Inspect the electrical connections and fuses.\")\n",
    "G1.add_node(\"Contact Technician\", type=\"end\", description=\"Call a certified EV technician.\")\n",
    "G1.add_node(\"Check Lights\", type=\"process\", description=\"Verify that all lights are functioning correctly.\")  # New Node\n",
    "\n",
    "# Add edges with yes/no decisions\n",
    "G1.add_edge(\"Start\", \"Battery Check\", answer=\"yes\")\n",
    "G1.add_edge(\"Battery Check\", \"Charge Battery\", answer=\"no\")\n",
    "G1.add_edge(\"Battery Check\", \"Electrical System Check\", answer=\"yes\")\n",
    "G1.add_edge(\"Electrical System Check\", \"Contact Technician\", answer=\"no\")\n",
    "G1.add_edge(\"Electrical System Check\", \"Start\", answer=\"yes\")  # Loop for when all is fine\n",
    "G1.add_edge(\"Start\", \"Check Lights\", answer=\"no\")  # New Edge\n",
    "\n",
    "# Save Graph G1 to JSON\n",
    "save_graph_to_json(G1, 'original_graph.json')\n",
    "\n",
    "# Create Graph G2 (Modified Instruction Graph)\n",
    "G2 = nx.DiGraph()\n",
    "\n",
    "# Add nodes with unique titles, types, and descriptions\n",
    "G2.add_node(\"Start\", type=\"start\", description=\"Inspect the vehicle for potential issues.\")\n",
    "G2.add_node(\"Battery Check\", type=\"multiple\", description=\"Check if the vehicle's battery is fully charged.\")\n",
    "G2.add_node(\"Replace Battery\", type=\"process\", description=\"Replace the battery if it cannot hold a charge.\")\n",
    "G2.add_node(\"Electrical System Check\", type=\"process\", description=\"Test the fuses and electrical wiring.\")\n",
    "G2.add_node(\"Contact Technician\", type=\"end\", description=\"Reach out to a professional technician for repairs.\")\n",
    "G2.add_node(\"Check Motor\", type=\"process\", description=\"Inspect the motor for unusual noise or damage.\")  # New Node\n",
    "G2.add_node(\"Check Lights\", type=\"process\", description=\"Ensure headlights and tail lights are operational.\")  # Modified Node\n",
    "\n",
    "# Add edges with yes/no decisions\n",
    "G2.add_edge(\"Start\", \"Battery Check\", answer=\"yes\")\n",
    "G2.add_edge(\"Battery Check\", \"Replace Battery\", answer=\"no\")  # Changed from \"Charge Battery\"\n",
    "G2.add_edge(\"Battery Check\", \"Electrical System Check\", answer=\"yes\")\n",
    "G2.add_edge(\"Electrical System Check\", \"Contact Technician\", answer=\"no\")\n",
    "G2.add_edge(\"Electrical System Check\", \"Check Motor\", answer=\"yes\")  # New Edge\n",
    "G2.add_edge(\"Check Motor\", \"Start\", answer=\"yes\")  # New loop\n",
    "G2.add_edge(\"Start\", \"Check Lights\", answer=\"no\")  # Retained Edge\n",
    "\n",
    "# Save Graph G2 to JSON\n",
    "save_graph_to_json(G2, 'curated_graph.json')\n",
    "\n",
    "print(\"Graphs saved to 'original_graph.json' and 'curated_graph.json'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Graph from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load graph from JSON\n",
    "def load_graph_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return nx.readwrite.json_graph.node_link_graph(data)\n",
    "\n",
    "# Load instruction graphs\n",
    "original_graph = load_graph_from_json('original_graph.json')\n",
    "curated_graph = load_graph_from_json('curated_graph.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text based edit distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_edit_distance(source_graph:nx.Graph, target_graph: nx.Graph) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Graph Edit Distance (GED) between two graphs.\n",
    "    Args:\n",
    "        source_graph: Source NetworkX graph\n",
    "        target_graph: Target NetworkX graph\n",
    "    Returns:\n",
    "        edit_distance: Graph Edit Distance between the two graphs\n",
    "    \"\"\"\n",
    "    # Here, you can define the node match criteria. It checks the type AND description attributes of the nodes.\n",
    "    node_match_criteria = lambda source_node, target_node: (\n",
    "        source_node.get(\"type\") == target_node.get(\"type\") and source_node.get(\"description\") == target_node.get(\"description\")\n",
    "    )\n",
    "    # Here, you can define the edge match criteria. It checks the answer attribute of the edges.\n",
    "    edge_match_criteria = lambda source_edge, target_edge: source_edge.get(\"answer\") == target_edge.get(\"answer\")\n",
    "\n",
    "    edit_distance = nx.graph_edit_distance(source_graph, target_graph, node_match=node_match_criteria, edge_match=edge_match_criteria)\n",
    "    return edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text based Graph Edit Distance (using node type and description): 10\n"
     ]
    }
   ],
   "source": [
    "graph_edit_distance = compute_edit_distance(original_graph, curated_graph)\n",
    "print(f\"Text based Graph Edit Distance (using node type and description): {int(graph_edit_distance)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use node semantic similarity to calculate edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added embeddings to the graphs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Prepare your AOAI environment\n",
    "load_dotenv()\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")\n",
    "\n",
    "def generate_embedding(text: str, model=\"text-embedding-3-large\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate embedding for a given text using the specified model.\n",
    "\n",
    "    Args:\n",
    "        text (str): input text to generate embedding for\n",
    "        model (str, optional): model to use for generating embedding. Defaults to \"text-embedding-3-large\".\n",
    "\n",
    "    Returns:\n",
    "        embedding: Generated embedding for the input text\n",
    "    \"\"\"\n",
    "    return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "# Compute cosine similarity between two embeddings\n",
    "def compute_cosine_similarity(source_embedding: np.ndarray, target_embedding: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two embeddings.\n",
    "\n",
    "    Args:\n",
    "        source_embedding (np.ndarray): Source embedding\n",
    "        target_embedding (np.ndarray): Target embedding\n",
    "\n",
    "    Returns:\n",
    "        similarity: Cosine similarity between the two embeddings\n",
    "    \"\"\"\n",
    "    return cosine_similarity([source_embedding], [target_embedding])[0][0]\n",
    "\n",
    "\n",
    "def add_embeddings_to_graph(graph: nx.Graph) -> nx.Graph:\n",
    "    \"\"\"\n",
    "    Generate embeddings for the node descriptions in the graph and add them to the graph.\n",
    "\n",
    "    Args:\n",
    "        graph (_type_): _description_\n",
    "    \"\"\"\n",
    "    for node_id in graph.nodes:\n",
    "        description = graph.nodes[node_id][\"description\"]\n",
    "        embedding = generate_embedding(description)\n",
    "        graph.nodes[node_id][\"embedding\"] = embedding\n",
    "    return graph\n",
    "\n",
    "\n",
    "# Load graphs\n",
    "original_graph = load_graph_from_json('original_graph.json')\n",
    "curated_graph = load_graph_from_json('curated_graph.json')\n",
    "\n",
    "# Add embeddings to the graphs\n",
    "add_embeddings_to_graph(original_graph)\n",
    "add_embeddings_to_graph(curated_graph)\n",
    "print(\"Added embeddings to the graphs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                      Similarity between \n",
      "                      'Inspect the electric vehicle for issues.' \n",
      "                      and \n",
      "                      'Inspect the vehicle for potential issues.'\n",
      "                      is 0.803 and above threshold 0.8\")\n",
      "                      \n",
      "\n",
      "                      Similarity between \n",
      "                      'Inspect the electrical connections and fuses.' \n",
      "                      and \n",
      "                      'Test the fuses and electrical wiring.'\n",
      "                      is 0.808 and above threshold 0.8\")\n",
      "                      \n",
      "Semantic Graph Edit Distance (threshold=0.8): 8\n"
     ]
    }
   ],
   "source": [
    "# Compute Graph Edit Distance with semantic similarity\n",
    "def compute_semantic_edit_distance(source_graph: nx.Graph, traget_graph: nx.Graph, threshold=0.8) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Graph Edit Distance (GED) between two graphs based on semantic similarity on node descriptions.\n",
    "\n",
    "    Args:\n",
    "        source_graph (nx.Graph): Source graph\n",
    "        traget_graph (nx.Graph): Target graph\n",
    "        threshold (float, optional): Threshold to determine the nodes as similar ones. Defaults to 0.8.\n",
    "\n",
    "    Returns:\n",
    "        graph_edit_disntance: Graph Edit Distance between the two graphs\n",
    "    \"\"\"\n",
    "    # Node match function based on semantic similarity\n",
    "    def node_match_criteria(source_node, target_node):\n",
    "        source_node_embedding = source_node.get(\"embedding\")\n",
    "        target_node_embedding = target_node.get(\"embedding\")\n",
    "        if source_node_embedding is not None and target_node_embedding is not None:\n",
    "            similarity = compute_cosine_similarity(source_node_embedding, target_node_embedding)\n",
    "            if similarity >= threshold:\n",
    "                # For debugging\n",
    "                print(f\"\"\"\n",
    "                      Similarity between \n",
    "                      '{source_node['description']}' \n",
    "                      and \n",
    "                      '{target_node['description']}'\n",
    "                      is {np.round(similarity, 3)} and above threshold {threshold}\")\n",
    "                      \"\"\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Edge match function based on exact 'answer' attribute\n",
    "    def edge_match_criteria(source_edge, target_edge):\n",
    "        return source_edge.get(\"answer\") == target_edge.get(\"answer\")\n",
    "\n",
    "    # Compute graph edit distance\n",
    "    graph_edit_disntance = nx.graph_edit_distance(\n",
    "        source_graph, traget_graph, node_match=node_match_criteria, edge_match=edge_match_criteria\n",
    "    )\n",
    "    return graph_edit_disntance\n",
    "\n",
    "# Compute the semantic graph edit distance\n",
    "threshold = 0.8\n",
    "semantic_ged = compute_semantic_edit_distance(original_graph, curated_graph, threshold)\n",
    "print(f\"Semantic Graph Edit Distance (threshold={threshold}): {int(semantic_ged)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
